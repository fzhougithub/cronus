You've hit on **two critical Airflow limitations** that often cause issues in production!

## **1. Airflow's Metadata Database Bottleneck**

**Yes, Airflow uses its own PostgreSQL/MySQL database for EVERYTHING**:

```python
# Every task heartbeat updates the database
# For 100 parallel tasks running for 1 hour:
# 100 tasks × 60 minutes × 1 update/minute = 6,000 updates/hour
# Plus logging, XComs, task states, etc.

# Your metadata database gets hammered during parallel runs:
1. task_instance table: Heartbeat updates every few seconds
2. log table: Every log line (if configured to DB)
3. xcom table: Any data passed between tasks
4. dag_run table: DAG run states
5. job table: Scheduler jobs
```

## **How Long Metadata Is Stored:**

By **default**, Airflow keeps **everything forever** unless you configure cleanup:

```bash
# Default retention (no cleanup):
dag_run → ∞ (forever)
task_instance → ∞  
log → ∞
xcom → ∞

# This is why Airflow metadata DB grows to 100GB+ in production!
```

## **The Critical Problem with Parallel Runs:**

Let me show you what happens with your parallel table copy:

```python
# With 20 parallel tasks copying for 2 hours:
# Each task: Updates task_instance every 10 seconds
20 tasks × (7200 seconds / 10) = 14,400 UPDATE queries
# Plus: 14,400 SELECT queries (scheduler checks)
# Plus: Logs (if DB-backed)
# Plus: XComs if used

# Your tiny Airflow metadata DB WILL choke!
```

## **Airflow Metadata Database Reality:**

| Component | Default Impact | Problem |
|-----------|---------------|---------|
| **Task Heartbeats** | ~6 updates/min per task | DB load grows linearly with parallelism |
| **Scheduler** | Constant polling | Additional SELECT queries every few seconds |
| **Logging** | Each log line → DB row | Massive growth with parallel tasks |
| **XComs** | Any data sharing → DB | Small data limits, adds to load |
| **Web Server** | UI queries | More SELECTs on task_instance |

## **Solutions: Optimize for Parallel Runs**

### **Option 1: Configure Airflow Properly**
```python
# airflow.cfg optimizations:

[core]
# Reduce heartbeat frequency (default: 5 seconds)
scheduler_heartbeat_sec = 30

# Use LocalExecutor instead of Celery for less DB load
executor = LocalExecutor

# Don't store logs in DB
remote_logging = True
remote_base_log_folder = s3://your-bucket/logs

[scheduler]
# Increase min_file_process_interval to reduce DB queries
min_file_process_interval = 60

# Reduce scheduler loops
scheduler_heartbeat_sec = 30

# Limit parallel tasks
max_active_runs_per_dag = 1
max_active_tasks_per_dag = 50

[database]
# Connection pool settings
sql_alchemy_pool_size = 10
sql_alchemy_max_overflow = 20
sql_alchemy_pool_recycle = 1800
```

### **Option 2: External Logging (ESSENTIAL)**
```python
# Configure S3/GCS logging instead of DB
# In airflow.cfg:
[core]
remote_logging = True
remote_base_log_folder = s3://airflow-logs-bucket/logs
remote_log_conn_id = aws_default
encrypt_s3_logs = False

# Or for GCS:
remote_base_log_folder = gs://airflow-logs-bucket/logs
```

### **Option 3: Cleanup Policies**
```python
# Add cleanup DAG to your Airflow:
from airflow.operators.python import PythonOperator
from airflow.models import Log, XCom, TaskInstance
from datetime import datetime, timedelta

def cleanup_old_records(**context):
    from airflow.settings import Session
    
    session = Session()
    
    # Delete old task instances (> 30 days)
    old_date = datetime.now() - timedelta(days=30)
    session.query(TaskInstance).filter(
        TaskInstance.end_date < old_date
    ).delete(synchronize_session=False)
    
    # Delete old logs
    session.query(Log).filter(
        Log.dttm < old_date
    ).delete(synchronize_session=False)
    
    # Delete old XComs  
    session.query(XCom).filter(
        XCom.execution_date < old_date
    ).delete(synchronize_session=False)
    
    session.commit()
    
# Schedule this DAG to run daily
```

### **Option 4: Tune PostgreSQL (if using container)**
```dockerfile
# Dockerfile for Airflow metadata DB:
FROM postgres:13

# Add these to postgresql.conf:
RUN echo "max_connections = 200" >> /usr/share/postgresql/postgresql.conf.sample
RUN echo "shared_buffers = 256MB" >> /usr/share/postgresql/postgresql.conf.sample
RUN echo "effective_cache_size = 1GB" >> /usr/share/postgresql/postgresql.conf.sample
RUN echo "maintenance_work_mem = 64MB" >> /usr/share/postgresql/postgresql.conf.sample
RUN echo "checkpoint_completion_target = 0.9" >> /usr/share/postgresql/postgresql.conf.sample
RUN echo "wal_buffers = 16MB" >> /usr/share/postgresql/postgresql.conf.sample
RUN echo "default_statistics_target = 100" >> /usr/share/postgresql/postgresql.conf.sample
```

### **Option 5: Minimalist DAG Design**
```python
# Design your DAG to minimize Airflow DB load:
def efficient_table_copy(**kwargs):
    """
    Minimal metadata impact design
    """
    # 1. ONE database connection per task (not per chunk)
    # 2. Log progress to external system (not Airflow logs)
    # 3. No XComs - use external storage
    # 4. Long-running chunks (fewer task updates)
    
    # External progress tracking (not Airflow Variables)
    progress_db = {
        'host': 'progress-tracker-db',
        'table': 'copy_progress'
    }
    
    # Batch logging (not line-by-line)
    log_batch = []
    log_batch.append(f"Started copy at {datetime.now()}")
    # ... process ...
    log_batch.append(f"Completed copy at {datetime.now()}")
    
    # Single log to Airflow (reduces DB writes)
    logging.info("\n".join(log_batch))
```

## **Immediate Fixes for Your Test Environment:**

```bash
# 1. Switch to LocalExecutor (if using default SQLite)
export AIRFLOW__CORE__EXECUTOR=LocalExecutor

# 2. Disable DB logging immediately
export AIRFLOW__CORE__REMOTE_LOGGING=False
export AIRFLOW__LOGGING__REMOTE_LOG_CONN_ID=""

# 3. Reduce scheduler frequency
export AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC=60
export AIRFLOW__SCHEDULER__MIN_FILE_PROCESS_INTERVAL=60

# 4. Add these to docker-compose.yml if using containers:
version: '3'
services:
  postgres:
    command: postgres -c 'max_connections=100' -c 'shared_buffers=256MB'
    
  airflow-scheduler:
    environment:
      - AIRFLOW__SCHEDULER__SCHEDULER_HEARTBEAT_SEC=60
      - AIRFLOW__CORE__EXECUTOR=LocalExecutor
```

## **Production Recommendation:**

```yaml
# For parallel table copies at scale:
1. Separate Metadata DB: Dedicated PostgreSQL instance (not container)
2. External Logging: S3/GCS for logs (never DB)
3. Limited Parallelism: Control via pools, not max_active_runs
4. Cleanup Strategy: Daily cleanup of old metadata
5. Monitoring: Watch DB connections and disk usage

# Database specs for 50+ parallel tasks:
- PostgreSQL 13+
- 4-8 CPU cores
- 8-16GB RAM  
- 100GB+ SSD storage
- Connection pool: 50-100 connections
```

## **Quick Diagnostic Commands:**

```sql
-- Check what's consuming space
SELECT schemaname, tablename, 
       pg_size_pretty(pg_total_relation_size(schemaname||'.'||tablename)) 
FROM pg_tables 
WHERE schemaname NOT IN ('pg_catalog', 'information_schema')
ORDER BY pg_total_relation_size(schemaname||'.'||tablename) DESC;

-- Check active connections
SELECT COUNT(*) FROM pg_stat_activity 
WHERE datname = 'airflow_metadata';

-- Find largest tables
SELECT nspname || '.' || relname AS "relation",
    pg_size_pretty(pg_total_relation_size(C.oid)) AS "total_size"
FROM pg_class C
LEFT JOIN pg_namespace N ON (N.oid = C.relnamespace)
WHERE nspname NOT IN ('pg_catalog', 'information_schema')
ORDER BY pg_total_relation_size(C.oid) DESC
LIMIT 10;
```

**Bottom line**: Your test Airflow's tiny metadata DB **will struggle** with massive parallel runs. You MUST:
1. Move logs out of the database
2. Reduce scheduler/worker chatter  
3. Implement cleanup
4. Consider a dedicated metadata DB for production

Would you like me to show you how to configure external logging or set up a cleanup DAG specifically for your environment?
